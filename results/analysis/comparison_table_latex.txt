\begin{table}[t]
\centering
\caption{Comparison of machine unlearning methods on CIFAR-10. Forget Acc measures accuracy on forgotten class (lower is better). Retain Acc measures accuracy on remaining classes (higher is better).}
\label{tab:unlearning_results}
\begin{tabular}{lccc}
\toprule
Method & Forget Acc (\%) $\downarrow$ & Retain Acc (\%) $\uparrow$ & $\Delta$ Utility \\
\midrule
Base Model (No Unlearning) & 91.83 $\pm$ 4.36 & 91.80 $\pm$ 3.77 & n/a \\
Uniform KL & 33.73 $\pm$ 46.33 & 92.04 $\pm$ 3.90 & +0.25\% \\
CE Ascent & 53.47 $\pm$ 46.56 & 91.83 $\pm$ 3.71 & +0.03\% \\
unlearn_noisy_retain_vit_cifar10_forget0 & 52.87 $\pm$ 33.75 & 92.31 $\pm$ 3.59 & +0.51\% \\
SalUn (Fan et al. 2024) & 0.10 $\pm$ 0.10 & \textbf{92.60 $\pm$ 3.36} & +0.80\% \\
SCRUB (Kurmanji et al. 2023) & \textbf{0.00 $\pm$ 0.00} & 91.84 $\pm$ 3.73 & +0.05\% \\
\bottomrule
\end{tabular}
\end{table}
