\begin{table}[t]
\centering
\caption{Comparison of machine unlearning methods on CIFAR-10. Forget Acc measures accuracy on forgotten class (lower is better). Retain Acc measures accuracy on remaining classes (higher is better).}
\label{tab:unlearning_results}
\begin{tabular}{lccc}
\toprule
Method & Forget Acc (\%) $\downarrow$ & Retain Acc (\%) $\uparrow$ & $\Delta$ Utility \
\midrule
Base Model (No Unlearning) & 91.83 $\pm$ 4.36 & 91.80 $\pm$ 3.77 & +0.00pp \
Uniform KL & 33.73 $\pm$ 46.33 & 92.04 $\pm$ 3.90 & +0.25pp \
CE Ascent & 53.47 $\pm$ 46.56 & 91.83 $\pm$ 3.71 & +0.03pp \
SalUn (Fan et al. 2024) & 58.27 $\pm$ 50.47 & 91.97 $\pm$ 4.01 & +0.17pp \
SCRUB (Kurmanji et al. 2023) & 53.87 $\pm$ 46.87 & 91.86 $\pm$ 3.71 & +0.06pp \
Noisy Retain-Only (Proxy) & 52.87 $\pm$ 33.75 & 92.31 $\pm$ 3.59 & +0.51pp \
\bottomrule
\end{tabular}
\end{table}
